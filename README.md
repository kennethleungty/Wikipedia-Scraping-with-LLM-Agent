# How to Scrape Wikipedia withÂ LLMs
## Combining LangChain's agents and tools with OpenAI's LLMs and function calling for the web scraping of Wikipedia

### Context
- The task of web scraping Wikipedia is a highly useful technique for extracting valuable information, thanks to its vast collection of structured and unstructured data. 
- Traditional tools like Selenium, while effective, tend to be manual and time-consuming.
- The impressive capabilities of large language models (LLMs) and the ability to connect them to the Internet have ushered in new possibilities in many use cases, including the domain of web scraping.
- In this article, we harness a synergistic combination of LLM agents, tools, and function calling to extract data from Wikipedia readily.

### Toolkit
- LangChain
  - Agents
  - Tools
  - Output Parsers
-  OpenAI
  - LLMs (specifically `gpt-3.5-turbo-1106`)
  - Function calling
